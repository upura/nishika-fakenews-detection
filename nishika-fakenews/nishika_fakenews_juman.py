# -*- coding: utf-8 -*-
"""nishika-fakenews-juman.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AxT1dwsXOy6YXT4iaQ8T7bVWjfjJAi2C
"""

!sudo apt -y update
!sudo apt -y install libeigen3-dev libprotobuf-dev protobuf-c-compiler

!sudo apt -y update
!sudo apt -y install libeigen3-dev libprotobuf-dev protobuf-c-compiler

!sudo apt -y update
!sudo apt -y install libeigen3-dev libprotobuf-dev protobuf-c-compiler
!sudo pip3 install -U pyknp
!cd /tmp
!wget https://github.com/ku-nlp/jumanpp/releases/download/v2.0.0-rc3/jumanpp-2.0.0-rc3.tar.xz
!tar -xvJof jumanpp-2.0.0-rc3.tar.xz

cd jumanpp-2.0.0-rc3

!mkdir build

cd build

# !rm CMakeCache.txt
!cmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local
!make
!sudo make install

!echo 'こんにちは，今日は晴れです' | jumanpp

from google.colab import drive
drive.mount('/content/drive')

cd ../../drive/MyDrive/fakenews

ls

# %%writefile wakachi.sh
# #!/bin/bash

# for line in $(cat -)
# do
#     echo "$line" | jumanpp | while read output
#     do
#       if [ "${output}" != "EOS" ]; then
#           word=$(echo ${output} | cut -d " " -f 1)
#           if [ "${word}" != "@" ]; then
#               result="${result} ${word}"
#           fi
#       else
#           echo $result
#       fi
#     done
# done

# !chmod 755 -R wakachi.sh

import pandas as pd


train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

train["text"] = train["text"].str[:3000]
test["text"] = test["text"].str[:3000]
# train.to_csv("train_short.csv", index=False)
# test.to_csv("test_short.csv", index=False)

from pyknp import Juman, BList, KNP


def jumman_parse(text):
    words = []
    sentences = [text]
    for sentence in sentences:
        try:
            juman = Juman("jumanpp", multithreading=True)
            sentence = sentence.replace("m(_ _)m", "")
            parse_result = juman.analysis(sentence)
        except:
            print("jumanpp error!!!!!!!!")
            print(sentence)
            continue
        # for v in parse_result:
        #     print(v.genkei)
    return " ".join([r.midasi for r in parse_result.mrph_list()])


jumman_parse("形態素解析は面白いです")

from tqdm import tqdm


res = []
for text in tqdm(train["text"]):
    res.append(jumman_parse(text))

res_test = []
for text in tqdm(test["text"]):
    res_test.append(jumman_parse(text))

train["text"] = res
test["text"] = res_test
train.to_csv("train_proc.csv", index=False)
test.to_csv("test_proc.csv", index=False)

# cat train_short.csv | cut -d "," -f 3 | ./wakachi.sh > train_pro.txt
# cat test_short.csv | cut -d "," -f 3 | ./wakachi.sh > test_pro.txt

train.isnull().sum()

test.isnull().sum()

